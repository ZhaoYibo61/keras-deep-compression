{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data loading and pre-processing\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Model related imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_if_not_exists(directory):\n",
    "    \"\"\"Creates a directory if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def save_loss_plots(history, directory):\n",
    "    \"\"\"Saves a plot of the training and test curves.\n",
    "    \"\"\"\n",
    "    for metric in list(['accuracy','loss']):\n",
    "        plt.figure()\n",
    "        plt.plot(history.history[metric])\n",
    "        plt.plot(history.history['val_'+metric])\n",
    "        plt.title('Model '+ metric)\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train','test'], loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, metric+'_plot.pdf'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# convert to float32, so that division does not make the features all zero\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# divide features by 255 so that pixels have value in the range of [0,1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices (one-hot encoding)\n",
    "n_output = 10\n",
    "y_train = np_utils.to_categorical(y_train, n_output)\n",
    "y_test = np_utils.to_categorical(y_test, n_output)\n",
    "\n",
    "print(\"X_Train: {}\\nX_Test:  {}\\nY_Train: {}\\nY_Test:  {}\"\\\n",
    "        .format(x_train.shape, x_test.shape,y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "optim = SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "#optim = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "#optim = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.get_weights():\n",
    "#    print(np.average(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=100, epochs=2, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 50\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.15, height_shift_range=0.15, horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=BS)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow(x_test, y_test, batch_size=BS)\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(x_train) // BS,\n",
    "                              epochs=50,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps= len(x_test) // BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir_if_not_exists('./checkpoints')\n",
    "save_loss_plots(history, './checkpoints')\n",
    "model.save_weights(os.path.join('./checkpoints',model_name, 'model.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
